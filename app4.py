import os
import json
import numpy as np
import pandas as pd
import ccxt
import tensorflow as tf
from openai import OpenAI
import matplotlib.pyplot as plt

# --- CONFIGURA√á√ÉO E CARREGAMENTO INICIAL ---

# Carregando o c√©rebro do nosso analista especialista uma √∫nica vez
# --- CONFIGURA√á√ÉO E CARREGAMENTO INICIAL ---
try:
    MODELO_DE_PADROES = tf.keras.models.load_model('meu_modelo_de_padroes.keras')
    # ATUALIZE ESTE DICION√ÅRIO PARA CONTER OS 5 PADR√ïES
    MAPA_ETIQUETAS = {
        0: 'Ombro-Cabe√ßa-Ombro',
        1: 'Topo Duplo',
        2: 'Sem Padr√£o',
        3: 'Bandeira de Alta',  # <-- Adicionado
        4: 'Bandeira de Baixa'  # <-- Adicionado
    }
    print("üß† Modelo de reconhecimento de padr√µes carregado com sucesso.")
except Exception as e:
    print("üö® Erro Cr√≠tico: N√£o foi poss√≠vel carregar o arquivo 'meu_modelo_de_padroes.keras'.")
    print("Certifique-se de que o modelo foi treinado e o arquivo est√° na mesma pasta.")
    exit()

# Configura√ß√£o do cliente do OpenRouter
try:
    CLIENTE_OPENROUTER = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key="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",
    )
    print("üîå Conex√£o com o OpenRouter estabelecida.")
except TypeError:
    print("üö® Erro Cr√≠tico: A vari√°vel de ambiente OPENROUTER_API_KEY n√£o foi encontrada.")
    exit()

# --- FERRAMENTAS ESPECIALISTAS QUE A LLM PODE USAR ---


def analisar_padrao_grafico(ticker: str):
    """
    Analisa os dados de mercado mais recentes de uma criptomoeda para identificar padr√µes gr√°ficos t√©cnicos.
    Use esta fun√ß√£o sempre que o usu√°rio pedir para 'analisar', 'verificar padr√µes' ou 'procurar por forma√ß√µes' em um gr√°fico.

    Args:
        ticker (str): O ticker do par a ser analisado, como 'BTC/USDT'.
    """
    print(f"\n[üõ†Ô∏è Ferramenta 'analisar_padrao_grafico' ativada para {ticker}]")

    # 1. Buscar dados reais
    print(f"Buscando dados reais para {ticker}...")
    try:
        exchange = ccxt.binance()
        ohlcv = exchange.fetch_ohlcv(ticker, '1d', limit=100)
        if len(ohlcv) < 100:
            return f"Erro: N√£o foram encontrados dados suficientes (m√≠nimo 100 dias) para {ticker}."
        dados_reais = pd.DataFrame(ohlcv, columns=[
                                   'timestamp', 'open', 'high', 'low', 'close', 'volume'])['close'].values
        print("Dados obtidos.")
    except Exception as e:
        return f"Erro ao buscar dados no ccxt: {e}"

    # 2. Preparar os dados para o modelo
    print("Normalizando e preparando os dados para an√°lise...")
    min_val = np.min(dados_reais)
    max_val = np.max(dados_reais)
    dados_normalizados = (dados_reais - min_val) / (max_val - min_val)
    dados_para_previsao = dados_normalizados.reshape(1, 100, 1)

    # 3. Fazer a previs√£o com o modelo treinado
    print("Analisando com o modelo de padr√µes...")
    previsao = MODELO_DE_PADROES.predict(dados_para_previsao)
    classe_prevista = np.argmax(previsao[0])
    nome_padrao_previsto = MAPA_ETIQUETAS[classe_prevista]
    confianca = previsao[0][classe_prevista] * 100

    resultado = f"An√°lise para {ticker} conclu√≠da. Padr√£o detectado: '{nome_padrao_previsto}' com {confianca:.2f}% de confian√ßa."
    print(f"[‚úÖ Resultado da ferramenta]: {resultado}")
    return resultado

# --- O AGENTE ORQUESTRADOR (LLM) ---


# --- O AGENTE ORQUESTRADOR (LLM) - VERS√ÉO CORRIGIDA ---

def agente_completo():
    """Fun√ß√£o principal que gerencia a conversa e as ferramentas."""

    # Descrevemos a ferramenta para a LLM
    tools = [
        {
            "type": "function",
            "function": {
                "name": "analisar_padrao_grafico",
                "description": "Analisa o gr√°fico de uma criptomoeda em busca de padr√µes t√©cnicos.",
                "parameters": {
                    "type": "object",
                    "properties": {"ticker": {"type": "string", "description": "O ticker do par, ex: 'BTC/USDT'"}},
                    "required": ["ticker"],
                },
            },
        }
    ]

    print("\n--- ü§ñ Agente de An√°lise T√©cnica Completo ---")
    print("Estou pronto. Pe√ßa para analisar um ativo (ex: 'analise o bitcoin pra mim'). Para sair, digite 'sair'.")

    # A principal mudan√ßa est√° neste loop.
    while True:
        entrada_usuario = input("\n> ")
        if not entrada_usuario.strip():  # Ignora se o usu√°rio apertar Enter sem digitar nada
            continue

        if entrada_usuario.lower() in ['sair', 'exit']:
            print("At√© logo!")
            break

        # Criamos a lista de mensagens aqui, garantindo que a primeira √© sempre do usu√°rio
        messages = [{"role": "user", "content": entrada_usuario}]

        try:
            # Envia para o OpenRouter
            response = CLIENTE_OPENROUTER.chat.completions.create(
                # Verifique se o nome do modelo est√° correto.
                # Se estiver usando um modelo do Google, ele deve ser algo como "google/gemini-pro-1.5"
                model="anthropic/claude-3-haiku",  # Um modelo robusto que aceita role:system
                messages=messages,
                tools=tools,
                tool_choice="auto",
            )

            response_message = response.choices[0].message

            if response_message.tool_calls:
                tool_call = response_message.tool_calls[0]
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)

                print(f"[ü§ñ LLM decidiu usar a ferramenta: '{function_name}']")

                # Executa a ferramenta
                function_response = analisar_padrao_grafico(ticker=function_args.get("ticker"))

                # Adiciona a chamada da ferramenta e a resposta da ferramenta ao hist√≥rico
                messages.append(response_message)
                messages.append(
                    {
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": function_response,
                    }
                )

                # Envia o hist√≥rico completo de volta para a LLM gerar uma resposta final
                print("\n[ü§ñ LLM est√° gerando a resposta final...]")
                final_response = CLIENTE_OPENROUTER.chat.completions.create(
                    model="anthropic/claude-3-haiku",
                    messages=messages
                )
                print(f"\nAgente diz: {final_response.choices[0].message.content}")
            else:
                # Se n√£o usou ferramenta, apenas responde
                print(f"\nAgente diz: {response_message.content}")

        except Exception as e:
            print(f"Ocorreu um erro ao chamar a API: {e}")


if __name__ == "__main__":
    agente_completo()
